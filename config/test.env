# Test Environment Configuration
# Dirty Spark Data Validation Pipeline

# =======================
# DATABASE CONFIGURATION (Testcontainers will override these)
# =======================
DB_HOST=localhost
DB_PORT=5432
DB_NAME=test_datawarehouse
DB_USER=test_pipeline
DB_PASSWORD=test_password
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
# Testcontainers will provide the actual DATABASE_URL

# =======================
# SPARK CONFIGURATION (Local mode for tests)
# =======================
SPARK_MASTER=local[2]
SPARK_APP_NAME=dirty-spark-pipeline-test
SPARK_DRIVER_MEMORY=1g
SPARK_EXECUTOR_MEMORY=1g
SPARK_EXECUTOR_CORES=1
SPARK_SQL_SHUFFLE_PARTITIONS=10
SPARK_SQL_ADAPTIVE_ENABLED=true

# Spark Checkpoints (use temp directory)
SPARK_CHECKPOINT_DIR=/tmp/test_checkpoints

# =======================
# KAFKA CONFIGURATION (Testcontainers)
# =======================
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CONSUMER_GROUP=test-consumer

# =======================
# STREAMING CONFIGURATION
# =======================
STREAM_TRIGGER_INTERVAL=1 second
STREAM_CHECKPOINT_LOCATION=/tmp/test_checkpoints/streaming

# =======================
# VALIDATION CONFIGURATION
# =======================
VALIDATION_RULES_PATH=tests/fixtures/test_validation_rules.yaml
SCHEMA_INFERENCE_SAMPLE_SIZE=100
SCHEMA_CONFIDENCE_THRESHOLD=0.90

# =======================
# BATCH PROCESSING
# =======================
BATCH_CHUNK_SIZE=100
BATCH_CONFIG_PATH=config/batch_config.yaml

# =======================
# LOGGING CONFIGURATION
# =======================
LOG_LEVEL=DEBUG
LOG_FORMAT=json

# =======================
# METRICS CONFIGURATION
# =======================
METRICS_PORT=8001
METRICS_ENABLED=false

# =======================
# FILE PATHS
# =======================
DATA_INPUT_PATH=tests/fixtures/input
DATA_OUTPUT_PATH=/tmp/test_output
QUARANTINE_PATH=/tmp/test_quarantine
